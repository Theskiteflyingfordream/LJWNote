### Redis与memcached的区别

1. **Redis 支持更丰富的数据类型（支持更复杂的应用场景）**。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。
2. **Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memcached 把数据全部存在内存之中，正因如此，redis有灾难恢复机制。Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。**
3. **Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。** 
4. **Memcached 过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。**



### Redis 的数据结构

**redisObject对象**

- redis的每一个键值对都表示为redisObject类型，里边持有指向底层数据结构实例的指针。

![image-20220830223904387](%E7%94%A8%E5%88%B0%E7%9A%84%E5%9B%BE%E7%89%87/image-20220830223904387.png)

- 为什么Redis会设计redisObject对象？

不同类型的key可以执行的命令不同，因此需要对key进行类型检查；

一些命令比如DEL是公共的，但是不同类型的键处理方式不同，并且同一种数据类型可能有不同的存储方式，命令的处理方式也会不同。这就需要根据数据类型的不同顶层数据结构进行多态处理。

**各数据类型的底层数据结构**

string底层数据结构为动态字符串，它又根据编码分为raw（一般字符串）或Rint（为了节约内存，Redis会将字符串表示的64位有符号整数编码为整数来进行储存）；

list底层数据结构为ziplist或quicklist，列表较小时，使用ziplist以节约空间；

set底层数据结构为intset或者hashtable，intset是只储存数字的小集合的特殊表示；

hash表底层数据结构为ziplist或者hashtable，ziplist是小hash表的特殊表示；

sorted set底层数据结构为ziplist或者skiplist格式，ziplist用于表示小的有序集合;

**底层数据结构实现**

**动态字符串SDS：**

- 头部+数据+“\0”；头部存储字符串长度等

- 好处在于：O(1)获取字符串长度；减少字符串的内存重新分配次数，C的普通字符串修改时需要重新释放和申请空间，SDS能够实现空间预分配和惰性空间释放（头部中有字段能够记录空余的，待后续使用）；二进制安全，C以“\0”作为结束标识，对于二进制文件，内容包含“\0”，而无法正常存取，SDS通过长度判断结束

**ZipList：**

![image-20220830230122817](%E7%94%A8%E5%88%B0%E7%9A%84%E5%9B%BE%E7%89%87/image-20220830230122817.png)

entry中的结构

![image-20220830230249076](%E7%94%A8%E5%88%B0%E7%9A%84%E5%9B%BE%E7%89%87/image-20220830230249076.png)

- 省内存？

相对于linkendlist，少了指针域的开销，遍历时通过prevlen定位下一个元素；相对于普通数组，元素大小取决于最大的元素，ziplist使用encoding字段，针对不同的encoding来细化存储大小

- 缺点

由于不预留内存空间，同时移出结点立即缩容，因此每次写都要内存分配

结点扩容，可能导致后面结点的prevlen字段扩容，从而造成链式反应

**QuickList：**

ZipList的双向链表

**Hashtable：**

数组存储，通过链表法解决冲突（渐进式rehash(Pdai)）

**IntSet：**

![image-20220830231605334](%E7%94%A8%E5%88%B0%E7%9A%84%E5%9B%BE%E7%89%87/image-20220830231605334.png)

- 整数集合升级

当在一个int16类型的整数集合中插入一个int32类型的值，整个集合的所有元素都会转换成32类型，为了减少开销，当这个int32被删除时不会降级。

**SkipList**

![image-20220830232035653](%E7%94%A8%E5%88%B0%E7%9A%84%E5%9B%BE%E7%89%87/image-20220830232035653.png)

增加了多个指针域，空间换时间；

- 为什么不用平衡树或者Hash

Hash不适合范围查找；平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，skipList实现与操作更加简单。



**特殊数据类型**

**HyperLogLogs**：使用少量固定的内存去存储并识别集合中的唯一元素，基于基数估算的算法

**Bitmap：**位图，极大的节省储存空间。



### 多路复用IO的单线程

文件事件处理器组成

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/6fuT3emWI5Jdhnbn0SIYAKmmRkT7fSLopeMz0k5G08luxEMmMJPalOngdDjFiaLDiaV1dcvq3A7Eorzj48JiaSJWQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

由于文件事件处理器是单线程方式运行的，所以我们一般都说 Redis 是单线程模型。

文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。

Redis的IO多路复用程序的所有功能都是通过包装操作系统的IO多路复用函数库来实现的。每当一个套接字准备好执行连接应答、写入、读取、关闭等操作时，就会产生一个文件事件，内核会将产生事件的Socket会交给 Redis 线程处理，它会调用套接字之前关联好的事件处理器来处理这些事件。

##### 为什么不用多线程

Redis中只有网络请求模块和数据操作模块是单线程的。而其他的如持久化存储模块等是多线程的。

多线程的目的，就是通过并发的方式来提升I/O的利用率和CPU的利用率，而Redis的操作基本都是基于内存的，因此CPU资源并不是Redis的性能瓶颈，而对于IO利用率，可以用IO多路复用来实现。

多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能

**为什么Redis 6.0 引入多线程**

在多路复用的IO模型中，在处理网络请求时，调用 select （其他函数同理，虽然同步非阻塞，但是read的过程需要阻塞）的过程会阻塞线程，如果并发量很高，此处可能会成为瓶颈。如果能采用多线程，使得网络处理的请求并发进行，就可以大大的提升性能。

同时由于多线程只用来处理网络请求，而数据的读写还是单线程，因此不会产生并发的问题。



### 过期数据

##### Redis 是如何判断数据是否过期的呢？

Redis 通过一个叫做过期字典（可以看作是 hash 表）来保存数据过期的时间。过期字典的键指向 Redis 数据库中的某个 key(键)，过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间 。

##### 过期的数据的删除策略了解么？

- **定时删除** ：为每个键设置一个定时器，一旦过期时间到了，则将键删除。这种策略对内存很友好，但是对 `CPU` 不友好，因为每个定时器都会占用一定的 `CPU` 资源。
- **惰性删除** ：不管键有没有过期都不主动删除，等到每次去获取键时再判断是否过期，如果过期就删除该键，否则返回键对应的值。这种策略对内存不够友好，可能会浪费很多内存。
- **定期扫描** ：系统每隔一段时间就定期扫描一次，发现过期的键就进行删除。这种策略相对来说是上面两种策略的折中方案，需要注意的是这个定期的频率要结合实际情况掌控好，使用这种方案有一个缺陷就是可能会出现已经过期的键也被返回。

在 `Redis` 当中，其选择的是策略 `2` 和策略 `3` 的综合使用。不过 `Redis` 的定期扫描只会扫描设置了过期时间的键，因为设置了过期时间的键 `Redis` 会单独存储，所以不会出现扫描所有键的情况

##### **Redis 内存淘汰机制**

| volatile-lru    | 根据 LRU 算法删除设置了过期时间的键，直到腾出可用空间。如果没有可删除的键对象，且内存还是不够用时，则报错 |
| --------------- | ------------------------------------------------------------ |
| allkeys-lru     | 根据 LRU 算法删除所有的键，直到腾出可用空间。如果没有可删除的键对象，且内存还是不够用时，则报错 |
| volatile-lfu    | 根据 LFU 算法删除设置了过期时间的键，直到腾出可用空间。如果没有可删除的键对象，且内存还是不够用时，则报错 |
| allkeys-lfu     | 根据 LFU 算法删除所有的键，直到腾出可用空间。如果没有可删除的键对象，且内存还是不够用时，则报错 |
| volatile-random | 随机删除设置了过期时间的键，直到腾出可用空间。如果没有可删除的键对象，且内存还是不够用时，则报错 |
| allkeys-random  | 随机删除所有键，直到腾出可用空间。如果没有可删除的键对象，且内存还是不够用时，则报错 |
| volatile-ttl    | 根据键值对象的 ttl 属性， 删除最近将要过期数据。如果没有，则直接报错 |
| noeviction      | 默认策略，不作任何处理，直接报错                             |

##### redis中LRU的实现(X)

每个对象中有一个lru属性，记录对象最后一次被访问的时间，维护了一个全局属性lru_clock，间隔一定时间对全局属性更新，删除时，根据两者之差来删除对象。redis并不是对所有对象都计算，而是抽样计算并删除，原因是对所有计算更耗时，而且可能会删除最近没被使用的热点数据。

##### redis中LFU的实现(X)

每一个键有8位的LFU计数器counter，当键被访问时

1. 提取 `0` 和 `1` 之间的随机数 `R`。
2. `counter` - 初始值（默认为 `5`），得到一个基础差值，如果这个差值小于 `0`，则直接取 `0`，为了方便计算，把这个差值记为 `baseval`。
3. 概率 `P` 计算公式为：`1/(baseval * lfu_log_factor + 1)`。
4. 如果 `R < P` 时，频次进行递增（`counter++`）。

如果访问频次 `counter` 只是一直在递增，那么迟早会全部都到 `255`，所以当某一个 `key` 一段时间不被访问之后，`counter` 也需要对应减少。

​	取出当前的时间戳和对象中的 `lru` 属性进行对比，计算出当前多久没有被访问到，比如计算得到的结果是 `100` 分钟没有被访问，然后再去除配置参数 `lfu_decay_time`，如果这个配置默认为 `1`也即是 `100/1=100`，代表 `100` 分钟没访问，所以 `counter` 就减少 `100`。



### Redis事务

不支持 roll back 的，因而不满足原子性的；

只有开启了持久化功能才满足持久性；

Redis 事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。



# 持久化

### RDB

父进程使用“写时复制技术”fork出子进程（写时复制技术即一般情况父进程和子进程会共享同一段物理内存，只有进程空间的某页的内容要发生变化时（父或子需要修改），才会将父进程的对应页内容复制一份给子进程。），由子进程将内存中数据集的快照写入磁盘，父进程响应其它命令（save为阻塞，bgsave可以响应其它），子进程会先将数据写入到 一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。

优势：恢复速度快，适合大规模数据复制

劣势：可能会丢失最后一次RDB后的数据；虽然使用写时复制技术，但是仍然会存在内存消耗。

### AOF

将Redis执行过的所有写指令记录下来(读操作不记录)（增量保存）， 只许追加文件但不可以改写文件，redis启动之初会根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作

##### 流程：

（1）客户端的请求写命令会被append追加到AOF缓冲区内；

（2）AOF缓冲区根据AOF持久化策略[always,everysec,no]将操作sync同步到磁盘的AOF文件中；

（3）AOF文件大小超过重写策略或手动重写时，会对AOF文件rewrite重写，压缩AOF文件容量；

（4）Redis服务重启时，会重新load加载AOF文件中的写操作达到数据恢复的目的；

（AOF和RDB同时开启，系统默认取AOF的数据）

AOF的rewrite（bgrewriteaof）：把rdb 的快照，以二级制的形式附在新的aof头部，作为已有的历史数据，替换掉原来的流水账操作。

##### no-appendfsync-on-rewrite

同时进行bgrewriteaof与主进程写aof，两者都会操作磁盘，而前者IO量大，会导致后者频繁阻塞，因此有no-appendfsync-on-rewrite=yes ,不写入aof文件只写入缓存，用户请求不会阻塞，但是在这段时间如果宕机会丢失这段时间的缓存数据，=no, 则是还是会把数据往磁盘里刷，但是遇到重写操作，可能会发生阻塞。

##### 触发机制，何时重写

auto-aof-rewrite-percentage：设置重写的基准值，文件达到100%时开始重写（文件是原来重写后文件的2倍时触发）

auto-aof-rewrite-min-size：设置重写的基准值，最小文件64MB。达到这个值开始重写。

如果Redis的AOF当前大小>= base_size +base_size*100% (默认)且当前大小>=64mb(默认)的情况下，Redis会对AOF进行重写。

##### 重写流程

（1）bgrewriteaof触发重写，判断是否当前有bgsave或bgrewriteaof在运行，如果有，则等待该命令结束后再继续执行。

（2）主进程fork出子进程执行重写操作，保证主进程不会阻塞。

（3）客户端的写请求同时写入aof_buf缓冲区和aof_rewrite_buf重写缓冲区保证原AOF文件完整以及新AOF文件生成期间的新的数据修改动作不会丢失。

（4）1).子进程写完新的AOF文件后，向主进程发信号，父进程更新统计信息。2).主进程把aof_rewrite_buf中的数据写入到新的AOF文件。

（5）使用新的AOF文件覆盖旧的AOF文件，完成AOF重写。



AOF优势：备份机制稳健，丢失数据概率小，同时aof是可读的日志文本，可以找出误操作。

AOF劣势：占用更多磁盘，备份速度慢。



##### 主从复制原理

Slave启动成功连接到master后会发送一个sync命令

Master接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令， 在后台进程执行完毕之后，master将传送整个数据文件到slave,以完成一次完全同步

全量复制：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。（注意redis在复制与发送期间都会在缓冲区记录此时执行的所有写命令，且在数据文件发送完毕后将其发送给从机，从机执行）

增量复制：Master继续将新的所有收集到的修改命令依次传给slave,完成同步

但是只要是重新连接master,一次完全同步（全量复制)将被自动执行



### 缓存一致性问题

[面试官：缓存一致性问题怎么解决？ (qq.com)](https://mp.weixin.qq.com/s?__biz=MzAwNDA2OTM1Ng==&mid=2453149368&idx=2&sn=75d6ba3523303d9cac1f1c367209ef89&scene=21#wechat_redirect)







### 缓存故障

[(95条消息) Redis 缓存穿透 + 缓存雪崩 + 缓存击穿的原因和解决方案_爱与不爱，一念之间-CSDN博客_redis缓存穿透解决方案](https://blog.csdn.net/womenyiqilalala/article/details/105205532)



### 使用redis进行秒杀

##### 解决超卖问题

使用watch(乐观锁)+mutil(事务)

在代码中首先watch，然后判断库存是否非空，然后使用事务（库存减一，用户集合中添加）

问题是会出现库存遗留

##### 同时解决库存遗留问题

将复杂的或者多步的redis操作，写为一个脚本，一次提交给redis执行，减少反复连接redis的次数。
LUA脚本是类似redis事务，使用redis的单线程特性，使得一次提交具有原子性，不会被其他命令插队。

在lua脚本中，先检查用户是否存在以及库存是否大于0，然后再减一；

