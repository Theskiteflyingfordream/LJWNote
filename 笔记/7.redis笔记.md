### Redis与memcached的区别

1. **Redis 支持更丰富的数据类型（支持更复杂的应用场景）**。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。
2. **Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memcached 把数据全部存在内存之中，正因如此，redis有灾难恢复机制。Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。**
3. **Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。** 
4. **Memcached 过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。**



### Redis 常见数据结构

##### string

1. **介绍** ：一种是int；另一种是自己构建了一种 **简单动态字符串**。相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据，二进制安全的（根据长度来判断结束而不是根据'\0'），并且获取字符串长度复杂度为 O(1)，内部结构实现上类似于Java的ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配.
2. **常用命令：** `set,get,strlen,exists,decr,incr,setex` 等等。
3. **应用场景：** 一般常用在需要计数的场景，比如用户的访问次数、热点文章的点赞转发数量等等。

##### list

1. **介绍** ：**list** 即是 **链表**。Redis 列表是简单的字符串列表，按照插入顺序排序。首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是ziplist，也即是压缩列表。它将所有的元素紧挨着一起存储，分配的是一块连续的内存。当数据量比较多的时候才会改成quicklist。因为普通的链表需要的附加指针空间太大，会比较浪费空间。比如这个列表里存的只是int类型的数据，结构prev和上还需要两个额外的指针next。

   （ziplist 将表中每一项存放在前后连续的地址空间内，每一项因占用的空间不同，而采用变长编码。由于内存是连续分配的，所以遍历速度很快）

   ![img](https://img2020.cnblogs.com/blog/980882/202005/980882-20200519190349244-1218774751.png)

   quickList是一个ziplist组成的双向链表。

   ![img](用到的图片/wps8CF1.tmp.jpg) 

   Redis将链表和ziplist结合起来组成了quicklist。也就是将多个ziplist使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。

2. **常用命令:** `rpush,lpop,lpush,rpop,lrange,llen` 等。

3. **应用场景:** 发布与订阅或者说消息队列、慢查询。

##### hash

1. **介绍** ：hash 类似于 JDK1.8 前的 HashMap，内部实现也差不多(数组 + 链表)。另外，hash 是一个 string 类型的 field 和 value 的映射表，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 比如我们可以 hash 数据结构来存储用户信息，商品信息等等。

   ![img](https://img2020.cnblogs.com/blog/980882/202005/980882-20200519231514858-1281005312.png)

2. **常用命令：** `hset,hmset,hexists,hget,hgetall,hkeys,hvals` 等。

3. **应用场景:** 系统中对象数据的存储。

#####  set

1. **介绍 ：** Redis的Set是string类型的无序集合。它底层其实是一个value为null的hash表，所以添加，删除，查找的复杂度都是O(1)。（intset可以使用二分查找去重）

![img](https://img2020.cnblogs.com/blog/980882/202005/980882-20200519233636368-1294338858.png)

![img](https://img2020.cnblogs.com/blog/980882/202005/980882-20200519234633601-1555960918.png)

1. **常用命令：** `sadd,spop,smembers,sismember,scard,sinterstore,sunion` 等。
2. **应用场景:** 需要存放的数据不能重复以及需要获取多个数据源交集和并集等场景

##### zset

1. **介绍：** 和 set 相比，sorted set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。ziplist、skiplist。zset容量少而且每一个元素不超过一定长度时，使用ziplist存储；否则使用 skiplist 存储。
2. **常用命令：** `zadd,zcard,zscore,zrange,zrevrange,zrem` 等。
3. **应用场景：** 需要对数据根据某个权重进行排序的场景。比如在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息。

##### bitmap

**介绍：** bitmap 存储的是连续的二进制数字（0 和 1），通过 bitmap, 只需要一个 bit 位来表示某个元素对应的值或者状态，key 就是对应元素本身 。我们知道 8 个 bit 可以组成一个 byte，所以 bitmap 本身会极大的节省储存空间。

**常用命令：** `setbit` 、`getbit` 、`bitcount`、`bitop`

**应用场景：** 适合需要保存状态信息（比如是否签到、是否登录...）并需要进一步对这些信息进行分析的场景。比如用户签到情况、活跃用户情况、用户行为统计（比如是否点赞过某个视频）。



### 多路复用IO的单线程

文件事件处理器组成

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/6fuT3emWI5Jdhnbn0SIYAKmmRkT7fSLopeMz0k5G08luxEMmMJPalOngdDjFiaLDiaV1dcvq3A7Eorzj48JiaSJWQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

由于文件事件处理器是单线程方式运行的，所以我们一般都说 Redis 是单线程模型。

文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。

Redis的IO多路复用程序的所有功能都是通过包装操作系统的IO多路复用函数库来实现的。每当一个套接字准备好执行连接应答、写入、读取、关闭等操作时，就会产生一个文件事件，内核会将产生事件的Socket会交给 Redis 线程处理，它会调用套接字之前关联好的事件处理器来处理这些事件。

##### 为什么不用多线程

Redis中只有网络请求模块和数据操作模块是单线程的。而其他的如持久化存储模块等是多线程的。

多线程的目的，就是通过并发的方式来提升I/O的利用率和CPU的利用率，而Redis的操作基本都是基于内存的，因此CPU资源并不是Redis的性能瓶颈，而对于IO利用率，可以用IO多路复用来实现。

多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能

**为什么Redis 6.0 引入多线程**

在多路复用的IO模型中，在处理网络请求时，调用 select （其他函数同理，虽然同步非阻塞，但是read的过程需要阻塞）的过程会阻塞线程，如果并发量很高，此处可能会成为瓶颈。如果能采用多线程，使得网络处理的请求并发进行，就可以大大的提升性能。

同时由于多线程只用来处理网络请求，而数据的读写还是单线程，因此不会产生并发的问题。



### 过期数据

##### Redis 是如何判断数据是否过期的呢？

Redis 通过一个叫做过期字典（可以看作是 hash 表）来保存数据过期的时间。过期字典的键指向 Redis 数据库中的某个 key(键)，过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间 。

##### 过期的数据的删除策略了解么？

- **定时删除** ：为每个键设置一个定时器，一旦过期时间到了，则将键删除。这种策略对内存很友好，但是对 `CPU` 不友好，因为每个定时器都会占用一定的 `CPU` 资源。
- **惰性删除** ：不管键有没有过期都不主动删除，等到每次去获取键时再判断是否过期，如果过期就删除该键，否则返回键对应的值。这种策略对内存不够友好，可能会浪费很多内存。
- **定期扫描** ：系统每隔一段时间就定期扫描一次，发现过期的键就进行删除。这种策略相对来说是上面两种策略的折中方案，需要注意的是这个定期的频率要结合实际情况掌控好，使用这种方案有一个缺陷就是可能会出现已经过期的键也被返回。

在 `Redis` 当中，其选择的是策略 `2` 和策略 `3` 的综合使用。不过 `Redis` 的定期扫描只会扫描设置了过期时间的键，因为设置了过期时间的键 `Redis` 会单独存储，所以不会出现扫描所有键的情况

##### **Redis 内存淘汰机制**

| volatile-lru    | 根据 LRU 算法删除设置了过期时间的键，直到腾出可用空间。如果没有可删除的键对象，且内存还是不够用时，则报错 |
| --------------- | ------------------------------------------------------------ |
| allkeys-lru     | 根据 LRU 算法删除所有的键，直到腾出可用空间。如果没有可删除的键对象，且内存还是不够用时，则报错 |
| volatile-lfu    | 根据 LFU 算法删除设置了过期时间的键，直到腾出可用空间。如果没有可删除的键对象，且内存还是不够用时，则报错 |
| allkeys-lfu     | 根据 LFU 算法删除所有的键，直到腾出可用空间。如果没有可删除的键对象，且内存还是不够用时，则报错 |
| volatile-random | 随机删除设置了过期时间的键，直到腾出可用空间。如果没有可删除的键对象，且内存还是不够用时，则报错 |
| allkeys-random  | 随机删除所有键，直到腾出可用空间。如果没有可删除的键对象，且内存还是不够用时，则报错 |
| volatile-ttl    | 根据键值对象的 ttl 属性， 删除最近将要过期数据。如果没有，则直接报错 |
| noeviction      | 默认策略，不作任何处理，直接报错                             |

##### redis中LRU的实现

每个对象中有一个lru属性，记录对象最后一次被访问的时间，维护了一个全局属性lru_clock，间隔一定时间对全局属性更新，删除时，根据两者之差来删除对象。redis并不是对所有对象都计算，而是抽样计算并删除，原因是对所有计算更耗时，而且可能会删除最近没被使用的热点数据。

##### redis中LFU的实现

每一个键有8位的LFU计数器counter，当键被访问时

1. 提取 `0` 和 `1` 之间的随机数 `R`。
2. `counter` - 初始值（默认为 `5`），得到一个基础差值，如果这个差值小于 `0`，则直接取 `0`，为了方便计算，把这个差值记为 `baseval`。
3. 概率 `P` 计算公式为：`1/(baseval * lfu_log_factor + 1)`。
4. 如果 `R < P` 时，频次进行递增（`counter++`）。

如果访问频次 `counter` 只是一直在递增，那么迟早会全部都到 `255`，所以当某一个 `key` 一段时间不被访问之后，`counter` 也需要对应减少。

​	取出当前的时间戳和对象中的 `lru` 属性进行对比，计算出当前多久没有被访问到，比如计算得到的结果是 `100` 分钟没有被访问，然后再去除配置参数 `lfu_decay_time`，如果这个配置默认为 `1`也即是 `100/1=100`，代表 `100` 分钟没访问，所以 `counter` 就减少 `100`。



### Redis事务

不支持 roll back 的，因而不满足原子性的；

只有开启了持久化功能才满足持久性；

Redis 事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。



# 持久化

### RDB

父进程使用“写时复制技术”fork出子进程（写时复制技术即一般情况父进程和子进程会共享同一段物理内存，只有进程空间的某页的内容要发生变化时（父或子需要修改），才会将父进程的对应页内容复制一份给子进程。），由子进程将内存中数据集的快照写入磁盘，父进程响应其它命令（save为阻塞，bgsave可以响应其它），子进程会先将数据写入到 一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。

优势：恢复速度快，适合大规模数据复制

劣势：可能会丢失最后一次RDB后的数据；虽然使用写时复制技术，但是仍然会存在内存消耗。

### AOF

将Redis执行过的所有写指令记录下来(读操作不记录)（增量保存）， 只许追加文件但不可以改写文件，redis启动之初会根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作

##### 流程：

（1）客户端的请求写命令会被append追加到AOF缓冲区内；

（2）AOF缓冲区根据AOF持久化策略[always,everysec,no]将操作sync同步到磁盘的AOF文件中；

（3）AOF文件大小超过重写策略或手动重写时，会对AOF文件rewrite重写，压缩AOF文件容量；

（4）Redis服务重启时，会重新load加载AOF文件中的写操作达到数据恢复的目的；

（AOF和RDB同时开启，系统默认取AOF的数据）

AOF的rewrite（bgrewriteaof）：把rdb 的快照，以二级制的形式附在新的aof头部，作为已有的历史数据，替换掉原来的流水账操作。

##### no-appendfsync-on-rewrite

同时进行bgrewriteaof与主进程写aof，两者都会操作磁盘，而前者IO量大，会导致后者频繁阻塞，因此有no-appendfsync-on-rewrite=yes ,不写入aof文件只写入缓存，用户请求不会阻塞，但是在这段时间如果宕机会丢失这段时间的缓存数据，=no, 则是还是会把数据往磁盘里刷，但是遇到重写操作，可能会发生阻塞。

##### 触发机制，何时重写

auto-aof-rewrite-percentage：设置重写的基准值，文件达到100%时开始重写（文件是原来重写后文件的2倍时触发）

auto-aof-rewrite-min-size：设置重写的基准值，最小文件64MB。达到这个值开始重写。

如果Redis的AOF当前大小>= base_size +base_size*100% (默认)且当前大小>=64mb(默认)的情况下，Redis会对AOF进行重写。

##### 重写流程

（1）bgrewriteaof触发重写，判断是否当前有bgsave或bgrewriteaof在运行，如果有，则等待该命令结束后再继续执行。

（2）主进程fork出子进程执行重写操作，保证主进程不会阻塞。

（3）客户端的写请求同时写入aof_buf缓冲区和aof_rewrite_buf重写缓冲区保证原AOF文件完整以及新AOF文件生成期间的新的数据修改动作不会丢失。

（4）1).子进程写完新的AOF文件后，向主进程发信号，父进程更新统计信息。2).主进程把aof_rewrite_buf中的数据写入到新的AOF文件。

（5）使用新的AOF文件覆盖旧的AOF文件，完成AOF重写。



AOF优势：备份机制稳健，丢失数据概率小，同时aof是可读的日志文本，可以找出误操作。

AOF劣势：占用更多磁盘，备份速度慢。



##### 主从复制原理

Slave启动成功连接到master后会发送一个sync命令

Master接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令， 在后台进程执行完毕之后，master将传送整个数据文件到slave,以完成一次完全同步

全量复制：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。（注意redis在复制与发送期间都会在缓冲区记录此时执行的所有写命令，且在数据文件发送完毕后将其发送给从机，从机执行）

增量复制：Master继续将新的所有收集到的修改命令依次传给slave,完成同步

但是只要是重新连接master,一次完全同步（全量复制)将被自动执行



### 缓存一致性问题

[面试官：缓存一致性问题怎么解决？ (qq.com)](https://mp.weixin.qq.com/s?__biz=MzAwNDA2OTM1Ng==&mid=2453149368&idx=2&sn=75d6ba3523303d9cac1f1c367209ef89&scene=21#wechat_redirect)



### 三种缓存读写策略

[3种常用的缓存读写策略 | JavaGuide](https://javaguide.cn/database/redis/3-commonly-used-cache-read-and-write-strategies.html#cache-aside-pattern-旁路缓存模式)



### 缓存故障

[(95条消息) Redis 缓存穿透 + 缓存雪崩 + 缓存击穿的原因和解决方案_爱与不爱，一念之间-CSDN博客_redis缓存穿透解决方案](https://blog.csdn.net/womenyiqilalala/article/details/105205532)



### 使用redis进行秒杀

##### 解决超卖问题

使用watch(乐观锁)+mutil(事务)

在代码中首先watch，然后判断库存是否非空，然后使用事务（库存减一，用户集合中添加）

问题是会出现库存遗留

##### 同时解决库存遗留问题

将复杂的或者多步的redis操作，写为一个脚本，一次提交给redis执行，减少反复连接redis的次数。
LUA脚本是类似redis事务，使用redis的单线程特性，使得一次提交具有原子性，不会被其他命令插队。

在lua脚本中，先检查用户是否存在以及库存是否大于0，然后再减一；

