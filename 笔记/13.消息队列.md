### 消息队列的作用

- 通过异步处理提高系统性能（减少响应所需时间）

- 削峰

先将短时间高并发产生的事务消息存储在消息队列中，然后后端服务再慢慢根据自己的能力去消费这些消息，这样就避免直接把后端服务打垮掉。

- 降低系统的耦合性

防止生产者与消费者的直接调用，两者都依赖于消息队列，新增模块或者修改模块就对其他模块影响较小，提高了扩展性。



### 消息队列的缺点

（1）系统的可用性降低：系统引用的外部依赖越多，越容易挂掉，如果MQ 服务器挂掉，那么可能会导致整套系统崩溃。这时就要考虑如何保证消息队列的高可用了

（2）系统复杂度提高：加入消息队列之后，需要保证消息没有重复消费、如何处理消息丢失的情况、如何保证消息传递的有序性等问题；

（3）数据一致性问题：A 系统处理完了直接返回成功了，使用者都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，就会导致数据不一致了



### 主题模式

主题模式是指，发布者将消息发送到指定主题中，订阅者需要提前订阅主题才能接受特定主题的消息。

在普通的单个队列中，一条消息只能被一个消费者消费，无法实现广播，因此它是没法用于主题模式的实现。

**Kafka主题模式的实现：**

- 单个队列中，每个消费者组维护一个offset，来实现一个消息能够被多个消费组的消费者消费。


![image-20221105011425833](%E7%94%A8%E5%88%B0%E7%9A%84%E5%9B%BE%E7%89%87/image-20221105011425833.png)

- 同时一个Topic可以拥有多个队列，这些队列可以分布在不同的Broker，从而实现负载均衡。
  - 生产者根据策略（也可以指定分区）将消息推到这个Topic的某一个分区下面；
  - 消费者组中的消费者们订阅相同的Topic；同一时刻，一个Topic中的队列只能被消费者组中的一个消费者消费；保证这个消费者组将Topic中的所有队列消费；消费者按照策略（也可以指定分区）消费某个分区的消息

https://www.cnblogs.com/cjsblog/p/9664536.html

<img src="%E7%94%A8%E5%88%B0%E7%9A%84%E5%9B%BE%E7%89%87/message-queue20210507200944439.png" alt="img" style="zoom:67%;" />

**RabbitMQ中主题模式的实现：**

- rabbitmq核心是队列模式，它没有消费者组的概念，每个消费者都独立地消费消息，因此RabbitMQ不支持队列的广播消费，即一个消息只能被一个消费者消费。多个消费者订阅同一个队列时，消息会被分摊给它们处理。

- rabbtimq的主题模式是通过Exchange和绑定去实现的

![Binding(绑定) 示意图](%E7%94%A8%E5%88%B0%E7%9A%84%E5%9B%BE%E7%89%87/70553134.jpg)

生产者将消息发送给交换器时，需要一个RoutingKey,当 BindingKey 和 RoutingKey 相匹配时，消息会被路由到对应的队列中；

Exchange有不同类型，对应着不同的路由规则；

消费者从订阅到的不同队列中去获取消息；



### Kafka中zookeeper的作用

- 注册Broker
- 注册消费者
- 维护Topic中分区及与Broker的对应关系
- 生产者负载均衡：使生产者的消息合理地发送到这些分布式的Broker上
- 消费者的负载均衡：维护分区与消费者组中的消费者的关系

[(15条消息) Kafka中Zookeeper的作用_一只慵懒的猫z的博客-CSDN博客_zookeeper在kafka中的作用](https://blog.csdn.net/peng_2297731313/article/details/124099789)





### 消息队列如何保证顺序消费？

**Kafka：**

- 生产者发送消息到不同的分区，会导致乱序，而同一个分区中消息是有序的，因此发送消息时可以指定分区或key（会根据key作hash到分区）。

- 消费者消费消息时，如果开多线程，会导致乱序，比如同一个订单号的不同消息，被多个线程处理，可能乱序，因此对同一类消息，需要单线程处理。

**RabbitMQ：**

- 一个队列对一个消费者
- 单线程



### 消息队列如何保证消息不丢？

**丢失有以下三种情况：**

- 生产者发送的消息因为网络原因丢失；

- 消息队列丢消息（宕机丢）

- 消费端丢（Kafka中消费端消费完消息之前就提交了offset，消费的过程中挂了，导致丢消息）

**Kafka的解决策略：**

- 生产者不能在调用send()之后，就认为发送成功，可以通过回调函数，当失败时，通过重试机制去重新send
- Kafka宕机丢消息，Kafka 为分区引入了多副本机制。分区中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。生产消费者只与leader交互，follower 副本用作备份，从 leader 副本中拉取消息进行同步。如果leader挂了，会选举follower，消息没有同步到follower也会导致丢消息，可以设置参数来保证消息不丢失：
  - 给topic设置 replication.factor 参数，这个值必须大于1，表示要求每个partition必须至少有2个副本。
  - 在kafka服务端设置 min.isync.replicas>1，这样配置代表消息至少要被写入到 2 个副本才算是被成功发送（当acks=all/-1才有效）
  - 在生产者端设置 acks=all ，表示只有所有 ISR 列表（里边不包含宕机的）的副本全部收到消息时，生产者才会接收到来自服务器的成功响应。
  - 设置 unclean.leader.election.enable = false。当 leader 副本发生故障时就不会从 follower 副本中和 leader 同步程度达不到要求的副本中选择出 leader ，这样降低了消息丢失的可能性
  - 为配合上述参数，生产者端需要有重试机制。
- 手动关闭自动提交 offset，每次在真正消费完消息之后再自己手动提交 offset 。 但是，这样会带来消息被重新消费的问题。比如你刚刚消费完消息之后，还没提交 offset，结果自己挂掉了，那么这个消息理论上就会被消费两次。

**RabbitMQ解决策略：**

- 生产者丢消息：

  - 可以选择使用RabbitMQ提供是事务功能，就是生产者在发送数据之前开启事务，然后发送消息，如果消息没有成功被RabbitMQ接收到，那么生产者会受到异常报错，这时就可以回滚事务，然后尝试重新发送。如果收到了消息，那么就可以提交事务。这种方式有明显的缺点，即RabbitMQ事务开启后，就会变为同步阻塞操作，生产者会阻塞等待是否发送成功，太耗性能会造成吞吐量的下降。
  - 可以开启confirm模式。在生产者那里设置开启了confirm模式之后，每次写的消息都会分配一个唯一的id，然后如果写入了RabbitMQ之中，RabbitMQ会给你回传一个ack消息，告诉你这个消息发送OK了。如果RabbitMQ没能处理这个消息，会回调你一个nack接口，可以在接口中实现重试。而且你可以结合这个机制知道自己在内存里维护每个消息的id，如果超过一定时间还没接收到这个消息的回调，那么你可以进行重发。

  事务机制和cnofifirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息RabbitMQ 接收了之后会异步回调你一个处理ack的接口通知你这个消息接收到了。

- 使用镜像队列集群模式，或者设置消息持久化到磁盘，设置持久化有两个步骤：

  - 创建queue的时候将其设置为持久化的，这样就可以保证RabbitMQ持久化queue的元数据，但是不会持久化queue里面的数据。
  - 发送消息的时候讲消息的deliveryMode设置为2，这样消息就会被设为持久化方式，此时RabbitMQ就会将消息持久化到磁盘上。 必须要同时开启这两个才可以。

  而且持久化可以跟生产的confirm机制配合起来，只有消息持久化到了磁盘之后，才会通知生产者ack，这样就算是在持久化之前RabbitMQ挂了，数据丢了，生产者收不到ack回调也会进行消息重发。

- 使用RabbitMQ提供的ack机制，首先关闭RabbitMQ的自动ack，然后每次在确保处理完这个消息之后，在代码里手动调用ack。这样就可以避免消息还没有处理完就ack。

  但是 RabbitMQ 并没有使用超时机制，RabbitMQ 仅通过与消费者的连接来确认是否需要重新发送消息，也就是说，只要连接不中断，RabbitMQ 会给消费者足够长的时间来处理消息。另外，采用手动确认消息的方式，我们也需要考虑一下几种特殊情况：

  - 如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ 会认为消息没有被消费，然后重新分发给下一个订阅的消费者，所以存在消息重复消费的隐患
  - 如果消费者接收到消息却没有确认消息，连接也未断开，则RabbitMQ认为该消费者繁忙，将不会给该消费者分发更多的消息



（消息确认机制上，kafka是offset commit，rabbitmq是ack）







### 消息队列如何保证不重复消费？

Kafka：

kafka出现消息重复消费的原因：服务端侧已经消费的数据没有成功提交 offset；

解决方案：消费服务做幂等校验，比如 Redis 的set、MySQL 的主键等天然的幂等功能。这种方法最有效。

RabbitMQ：

同上，做幂等



### 如何保证高可用？

**RabbitMQ**

- 单机模式

- 普通集群模式：在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你创建的queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息以及交换器数据，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。（不同的queue所在的节点可能不同，创建的时候在哪就在那）

  这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。缺点在于，无高可用，queue所在实例挂了就没了，同时RabbitMQ 内部会产生大量的数据传输。

  <img src="%E7%94%A8%E5%88%B0%E7%9A%84%E5%9B%BE%E7%89%87/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2E3NDUyMzM3MDA=,size_16,color_FFFFFF,t_70.png" alt="img" style="zoom: 50%;" />

- 镜像队列集群模式：
  - 队列有master队列和slave队列，分布在不同的broker上，mater挂了，会选举slave，实现高可用；
  - 生产者只把消息丢给master，master会将元数据以及消息同步给slave；消费者可以选择master或者slave进行连接，消费请求会路由到master，master返回消息（如果存在slave没有同步这个消息，则消费失败）；消费完后，master发出删除消息，slave中将其删除。
  - 不同的队列master可以分布在不同的broker上，实现负载均衡；

​		<img src="%E7%94%A8%E5%88%B0%E7%9A%84%E5%9B%BE%E7%89%87/2226025-20210527172158028-453119641.png" alt="img" style="zoom:50%;" />



**Kafka**

拥有分区，是天然的分布式消息队列；同时使用replica机制，实现了高可用（见如何保证消息不丢的第二点）



### 如何处理消息堆积情况?

场景题：几千万条数据在MQ里积压了七八个小时。

**原因**

生产速度与消费速度不匹配，比如消费能力弱，或者消费端由于中间依赖挂了，消费失败反复重试。

**临时扩容，快速处理积压的消息**

（1）先修复 consumer 的问题，确保其恢复消费速度，然后将现有的 consumer 都停掉；

（2）临时创建原先 N 倍数量的 queue ，然后写一个临时分发数据的消费者程序，将该程序部署上去消费队列中积压的数据，消费之后不做任何耗时处理，直接均匀轮询写入临时建立好的 N 倍数量的 queue 中；

（3）接着，临时征用 N 倍的机器来部署 consumer，每个 consumer 消费一个临时 queue 的数据

（4）等快速消费完积压数据之后，恢复原先部署架构 ，重新用原先的 consumer 机器消费消息。

这种做法相当于临时将 queue 资源和 consumer 资源扩大 N 倍，以正常 N 倍速度消费。
**数据过期丢失？**

如果使用的是 rabbitMQ，并且设置了ttl，消息在 queue 里积压超过一定的时间会被 rabbitmq 清理掉，导致数据丢失。这种情况下，实际上队列中没有什么消息挤压，而是丢了大量的消息。所以就不能说增加 consumer 消费积压的数据了，这种情况可以采取 “批量重导” 的方案来进行解决。在流量低峰期，写一个程序，手动去查询丢失的那部分数据，然后将消息重新发送到mq里面，把丢失的数据重新补回来。
**MQ快写满了？**

临时扩容执行太慢，需要使用“丢弃+批量重导”。首先，临时写个程序，连接到mq里面消费数据，消费一个丢弃一个，快速消费掉积压的消息，降低MQ的压力，然后在流量低峰期时去手动查询重导丢失的这部分数据。



### 消息队列推和拉两种模式

**推模式：**

推模式指的是消息从 Broker 推向 Consumer，即 Consumer 被动的接收消息，由 Broker 来主导消息的发送。

优点：实时性高、消费者使用简单

缺点：推送速率难以适应消费速率、身为 Broker 很难平衡每个消费者的推送速率

**拉模式：**

拉模式指的是 Consumer 主动向 Broker 请求拉取消息，即 Broker 被动的发送消息给 Consumer。

优点：消费者可以根据自身的情况来发起拉取消息的请求（可以批量发送）、Broker轻松

缺点：消息延迟、消息忙请求（忙请求就是比如消息隔了几个小时才有，那么在几个小时之内消费者的请求都是无效的，在做无用功）



RockeMQ和Kafka用的是拉模式，使用“长轮询”机制。通过消费者等待消息，当有消息的时候 Broker 会直接返回消息，如果没有消息都会采取延迟处理的策略，并且为了保证消息的及时性，在对应队列或者分区有新消息到来的时候都会提醒消息来了，及时返回消息。

Rabbitmq采用的是推模式

https://segmentfault.com/a/1190000023854950



### 死信队列？

死信队列是一种特殊的消息队列，用于存放那些无法被消费者处理的消息。死信队列可以帮助我们处理那些无法被正常消费的消息，避免它们一直占用消息队列的资源或者被丢弃，从而提高系统的可靠性和稳定性。

死信队列可以应用于多种场景，例如：

1. 消息消费失败：当消费者在处理消息时发生异常或者处理失败时，可以将这条消息发送到死信队列中，以便后续处理。
2. 消息超时：当消息的TTL过期时，可以将这条消息发送到死信队列中。
3. 消息重试失败：当消息被重试多次仍然无法被成功处理时，可以将这条消息发送到死信队列中。
4. 消息格式错误：当消息格式不合法时，可以将这条消息发送到死信队列中。



### Kafka为什么速度快？

- 顺序写入。每一个Partition其实都是一个文件 ，收到消息后Kafka会把数据插入到文件末尾，顺序写入的消息读取也是顺序的，借助OS的一些优化（页缓存，预读，write back），减少了实际IO的频率 以及 磁盘寻道的时间。

- 网络IO使用零拷贝提高性能
- 网络传输过程中使用批量压缩以及批量发送



### Kafka、RabbitMQ、RocketMQ的区别？